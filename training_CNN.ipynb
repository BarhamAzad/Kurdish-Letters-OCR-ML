{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "447e31de",
   "metadata": {},
   "source": [
    "# Kurdish Letter OCR - CNN Model\n",
    "\n",
    "## Overview\n",
    "This notebook trains and evaluates a Convolutional Neural Network (CNN) to classify Kurdish letters (EEE, LLL, OOO, RRR, VVV) from grayscale images.\n",
    "\n",
    "## Pipeline\n",
    "1. **Configuration** - Set up parameters and load dependencies\n",
    "2. **Model Architecture** - Define CNN structure\n",
    "3. **Load Data** - Read and preprocess images from folders\n",
    "4. **Data Preparation** - Normalize, split into train/test sets\n",
    "5. **Training** - Train model for 20 epochs\n",
    "6. **Evaluation** - Test accuracy on unseen data\n",
    "\n",
    "## Key Features\n",
    "- **Input**: 64x64 grayscale images\n",
    "- **Output**: 5 Kurdish letter classes\n",
    "- **Model**: 3-layer CNN with pooling and fully connected layers\n",
    "- **Optimizer**: Adam with learning rate 0.001\n",
    "- **Device**: GPU support (falls back to CPU)\n",
    "\n",
    "## Expected Results\n",
    "- Training accuracy increases each epoch\n",
    "- Final test accuracy typically 85-95% depending on data quality\n",
    "- Model weights saved for later inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fe3a56",
   "metadata": {},
   "source": [
    "## Libraries required\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1881c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os                                    # File and directory operations\n",
    "import cv2                                   # OpenCV - Image reading, resizing, processing\n",
    "import numpy as np                           # NumPy - Array operations and numerical computing\n",
    "import torch                                 # PyTorch - Deep learning framework\n",
    "import torch.nn as nn                        # PyTorch neural network modules\n",
    "import torch.optim as optim                  # PyTorch optimization algorithms (Adam, SGD, etc.)\n",
    "from torch.utils.data import DataLoader, TensorDataset  # Data loading utilities\n",
    "from sklearn.model_selection import train_test_split    # Train/test data splitting\n",
    "from sklearn.preprocessing import LabelEncoder          # Categorical label encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01240ad1",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Sets up all necessary parameters, imports, and directories for the Kurdish letter classification model.\n",
    "\n",
    "**Parameters:**\n",
    "- `IMG_SIZE`: 64x64 pixels (image dimensions)\n",
    "- `CHANNELS`: 1 (grayscale images)\n",
    "- `EPOCHS`: 20 training iterations\n",
    "- `BATCH_SIZE`: 32 images per batch\n",
    "- `LEARNING_RATE`: 0.001 for Adam optimizer\n",
    "\n",
    "**Categories:** 5 Kurdish letters (EEE, LLL, OOO, RRR, VVV)\n",
    "\n",
    "**Device:** Uses GPU if available, otherwise CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91c6bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 64\n",
    "CHANNELS = 1\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "DATA_DIR = \".\"\n",
    "MODEL_PATH = \"kurdish_letter_model_pytorch.pth\"\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Categories in alphabetical order (for consistent label encoding)\n",
    "CATEGORIES = [\n",
    "    {\"folder\": \"EEE_letters\", \"prefix\": \"eee_letter_\"},\n",
    "    {\"folder\": \"LLL_letters\", \"prefix\": \"lll_letter_\"},\n",
    "    {\"folder\": \"OOO_letters\", \"prefix\": \"ooo_letter_\"},\n",
    "    {\"folder\": \"RRR_letters\", \"prefix\": \"rrr_letter_\"},\n",
    "    {\"folder\": \"VVV_letters\", \"prefix\": \"vvv_letter_\"}\n",
    "]\n",
    "\n",
    "EXTENSIONS = [\".png\", \".jpg\", \".jpeg\", \".bmp\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d321e7",
   "metadata": {},
   "source": [
    "## Model Architecture\n",
    "\n",
    "Defines the KurdishCNN - a Convolutional Neural Network for image classification.\n",
    "\n",
    "**Architecture:**\n",
    "- **Input**: 1x64x64 grayscale images\n",
    "- **Convolutional Layers**: 3 layers with ReLU activation\n",
    "  - Conv1: 32 filters\n",
    "  - Conv2: 64 filters\n",
    "  - Conv3: 64 filters\n",
    "- **Pooling**: MaxPool2d (2x2) after each convolution\n",
    "- **Fully Connected Layers**:\n",
    "  - FC1: Flattened features → 64 neurons (with dropout)\n",
    "  - FC2: 64 → 5 classes (Kurdish letters)\n",
    "\n",
    "**Total parameters**: ~500K trainable weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9ae13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KurdishCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(KurdishCNN, self).__init__()\n",
    "\n",
    "        # Convolutional Layers\n",
    "        # Input: (1, IMG_SIZE, IMG_SIZE)\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Dynamically calculate the input features for the linear layer.\n",
    "        # Pass a dummy tensor through the conv layers to get the output size.\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(1, 1, IMG_SIZE, IMG_SIZE)\n",
    "            x = self.pool(self.relu(self.conv1(dummy_input)))\n",
    "            x = self.pool(self.relu(self.conv2(x)))\n",
    "            x = self.pool(self.relu(self.conv3(x)))\n",
    "            num_flat_features = x.numel() // x.shape[0] # x.shape[0] is batch size 1\n",
    "\n",
    "        # Fully Connected Layers\n",
    "        self.fc1 = nn.Linear(num_flat_features, 64)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = self.pool(self.relu(self.conv3(x)))\n",
    "\n",
    "        x = x.view(x.size(0), -1) # Flatten the tensor dynamically\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5268b3f5",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "\n",
    "Loads and preprocesses all images from the letter category folders.\n",
    "\n",
    "**Process:**\n",
    "1. Scans all \"_letters\" folders\n",
    "2. Reads images in supported formats (PNG, JPG, JPEG, BMP)\n",
    "3. Converts to grayscale\n",
    "4. Resizes to 64x64 pixels\n",
    "5. Stores image arrays and corresponding labels\n",
    "\n",
    "**Output:**\n",
    "- `X`: Image array data\n",
    "- `y`: Corresponding class labels (folder names)\n",
    "- Total images loaded across all 5 categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c97871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"Load and preprocess images from category folders.\"\"\"\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    print(\"Loading and Preprocessing Images...\")\n",
    "\n",
    "    for category_idx, cat in enumerate(CATEGORIES):\n",
    "        folder_path = os.path.join(DATA_DIR, cat[\"folder\"])\n",
    "\n",
    "        if not os.path.exists(folder_path):\n",
    "            print(f\"Warning: Folder '{folder_path}' not found. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        count = 0\n",
    "        # Load all image files in the folder\n",
    "        for filename in os.listdir(folder_path):\n",
    "            # Check if file has a supported image extension\n",
    "            if not any(filename.lower().endswith(ext) for ext in EXTENSIONS):\n",
    "                continue\n",
    "\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "\n",
    "            # Skip if it's a directory\n",
    "            if not os.path.isfile(image_path):\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                img_array = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "                if img_array is None:\n",
    "                    continue\n",
    "\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "                data.append(new_array)\n",
    "                labels.append(cat[\"folder\"])\n",
    "                count += 1\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"  Error processing {image_path}: {e}\")\n",
    "\n",
    "        print(f\"Loaded {count} images for class: {cat['folder']}\")\n",
    "\n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657e53a6",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Preprocesses the loaded images and prepares them for training and testing.\n",
    "\n",
    "**Preprocessing Steps:**\n",
    "1. **Normalization** - Scale pixel values from [0-255] to [0-1] by dividing by 255\n",
    "2. **Reshaping** - Reshape data to (N, IMG_SIZE, IMG_SIZE, CHANNELS) format\n",
    "3. **Transpose** - Reorder dimensions to PyTorch format (N, CHANNELS, IMG_SIZE, IMG_SIZE)\n",
    "4. **Tensor Conversion** - Convert NumPy arrays to PyTorch tensors (float32 for images, long for labels)\n",
    "\n",
    "**Label Encoding:**\n",
    "- Converts categorical class names to numeric labels:\n",
    "  - EEE_letters → 0\n",
    "  - LLL_letters → 1\n",
    "  - OOO_letters → 2\n",
    "  - RRR_letters → 3\n",
    "  - VVV_letters → 4\n",
    "\n",
    "**Data Splitting:**\n",
    "- Train/Test split: 80% training, 20% testing\n",
    "- Creates DataLoaders for batch processing\n",
    "- Batch size: 32 images per batch\n",
    "- Shuffles training data for better learning\n",
    "\n",
    "**Output Shapes:**\n",
    "- Training set: (N_train, 1, 64, 64)\n",
    "- Test set: (N_test, 1, 64, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4364be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- DATA PREPARATION ---\n",
    "X, y = load_data()\n",
    "\n",
    "if len(X) == 0:\n",
    "    print(\"No images loaded. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "# Normalize and reshape for PyTorch (N, 1, 64, 64)\n",
    "X = X / 255.0\n",
    "X = X.reshape(-1, IMG_SIZE, IMG_SIZE, CHANNELS)\n",
    "X = np.transpose(X, (0, 3, 1, 2))\n",
    "\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "y_tensor = torch.tensor(y_encoded, dtype=torch.long)\n",
    "\n",
    "print(f\"Classes found: {le.classes_}\")\n",
    "\n",
    "# Split and create data loaders\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"Training shape: {X_train.shape}\")\n",
    "print(f\"Testing shape: {X_test.shape}\")\n",
    "\n",
    "# --- MODEL INITIALIZATION ---\n",
    "model = KurdishCNN(num_classes=len(CATEGORIES)).to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2daaf12e",
   "metadata": {},
   "source": [
    "## Training & Evaluation\n",
    "\n",
    "Trains the CNN model on the training dataset and evaluates performance.\n",
    "\n",
    "**Training Process:**\n",
    "1. Creates and initializes the model\n",
    "2. Sets up loss function (CrossEntropyLoss) and optimizer (Adam)\n",
    "3. For each of 20 epochs:\n",
    "   - Forward pass through model\n",
    "   - Calculate loss on training batch\n",
    "   - Backward pass (backpropagation)\n",
    "   - Update weights via gradient descent\n",
    "   - Track training loss and accuracy\n",
    "4. Evaluates model on test set (20% of data)\n",
    "5. Saves trained model weights to file\n",
    "\n",
    "**Metrics:**\n",
    "- Displays loss and accuracy per epoch\n",
    "- Final test accuracy on unseen data\n",
    "- Model saved as `kurdish_letter_model_pytorch.pth`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c287cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- TRAINING LOOP ---\n",
    "print(\"\\nStarting Training...\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_acc = 100 * correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {epoch_acc:.2f}%\")\n",
    "\n",
    "# --- EVALUATION ---\n",
    "print(\"\\nEvaluating on Test Set...\")\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Final Test Accuracy: {100 * correct / total:.2f}%\")\n",
    "\n",
    "# --- SAVE MODEL ---\n",
    "torch.save(model.state_dict(), MODEL_PATH)\n",
    "print(f\"Model saved as '{MODEL_PATH}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
